# -*- coding: utf-8 -*-
"""Air quality forecasting

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FYt5d4SJtmDnBgejVlxDNYG2OmUi0S1W

#Data Processing (aqi)
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import time
import datetime
import matplotlib.pyplot as plt
# %matplotlib notebook

from google.colab import files
data = files.upload()
df = pd.read_csv('aqi_all.csv', na_values=['None'])
df

df.head()

df.isnull().sum()

df.fillna(-1.0, inplace=True)

df.info()

df['From Date'] = df['From Date'].apply(lambda x: x[:-3])

df['Timestamp'] = df['From Date'].apply(pd.Timestamp)

df.drop(columns=['To Date','From Date'],inplace=True)

df.index = df['Timestamp']

del df['Timestamp']

df.columns

df.sort_index(inplace=True)

df.reset_index(inplace=True)

df.drop_duplicates(inplace=True)

sensors = ['Alipur', 'AnandVihar', 'AshokVihar', 'Bawana', 'DrKarniShootingRange',
       'DTU', 'DwarkaSector8', 'IHBASDilshadGarden', 'Jahangirpuri',
       'JawaharlalNehruStadium', 'MajorDhyanChandNationalStadium',
       'MandirMarg', 'Mundka', 'Najafnagar', 'Narela', 'NehruNagar',
       'OkhlaPhase2', 'Patparganj', 'PunjabiBagh', 'Pusa', 'RKPuram', 'Rohini',
       'Shadipur', 'Sirifort', 'SoniaVihar', 'SriAurobindoMarg', 'VivekVihar',
       'Wazirpur']

df.head()

#df = df[df.columns.isin(sensors)]

df_final = df.copy()
#[['From Timestamp', 'Alipur', 'Anand_Vihar', 'Ashok_Vihar']]

df_final.head()

df_final.shape

df_final.info()

df_final.index = df_final['Timestamp']

train = df_final.loc['2019-01-01 00:00:00':'2020-06-30 23:00:00',:]
test = df_final.loc['2020-07-01 00:00:00':'2020-12-31 23:00:00',:]

train.isnull().sum()

df_final = pd.concat([train,test],axis=0)

df_final.shape

del df_final['Timestamp']

df_final = df_final.add_prefix('aqi_')

df_final.head()

"""#Data Processing (meo)"""

from google.colab import files
data = files.upload()
df_at = pd.read_csv('weather_all.csv', na_values=['None'])
df_at

df_at.head()

df_at.isnull().sum()

df_at.fillna(0.0, inplace=True)

df_at.info()

df_at['Timestamp'] = df_at['From Date'].apply(pd.Timestamp)

del df_at['To Date']

del df_at['From Date']

df_at.columns

df_meo = df_at.copy()

df_meo.index = df_meo['Timestamp']

del df_meo['Timestamp']

#df_final.sort_values(['From Timestamp','To Timestamp'])

df_meo.head()

df_meo.shape

df_meo.info()

train2 = df_meo.loc['2019-01-01 00:00:00':'2020-06-30 23:00:00',:]
test2 = df_meo.loc['2020-07-01 00:00:00':'2020-12-31 23:00:00',:]

train2.isnull().sum()

df_meo = pd.concat([train2,test2],axis=0)

df_meo.shape

#df_meo = df_meo.add_prefix('at_')
#df_meo.rename(columns = {'Alipur': 'meo_Alipur', 'Anand_Vihar': 'meo_Anand_Vihar', 'Ashok_Vihar': 'meo_Ashok_Vihar'}, inplace = True)

df_meo.head()

"""#Combining datasets and function definitions"""

from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import LinearRegression, RidgeCV, MultiTaskLassoCV, LassoCV
from sklearn.metrics import mean_squared_error
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR
from sklearn.multioutput import MultiOutputRegressor
from sklearn.ensemble import GradientBoostingRegressor
import lightgbm as lgb
import tensorflow as tf

df_aqi = pd.DataFrame(df_final)

df_aqi.head()

sensors = ['Alipur', 'AnandVihar', 'AshokVihar', 'Bawana', 'DrKarniShootingRange',
       'DTU', 'DwarkaSector8', 'IHBASDilshadGarden', 'Jahangirpuri',
       'JawaharlalNehruStadium', 'MajorDhyanChandNationalStadium',
       'MandirMarg', 'Mundka', 'Najafnagar', 'Narela', 'NehruNagar',
       'OkhlaPhase2', 'Patparganj', 'PunjabiBagh', 'Pusa', 'RKPuram', 'Rohini',
       'Shadipur', 'Sirifort', 'SoniaVihar', 'SriAurobindoMarg', 'VivekVihar',
       'Wazirpur']

df = pd.merge(df_aqi,df_meo,how='left',left_index=True,right_index=True)

df.replace(0.0,np.NaN,inplace=True)

df.head()

def masked_mse_tf(preds, labels, null_val=np.nan):
    """
    Accuracy with masking.
    :param preds:
    :param labels:
    :param null_val:
    :return:
    """
    if np.isnan(null_val):
        mask = ~tf.is_nan(labels)
    else:
        mask = tf.not_equal(labels, null_val)
    mask = tf.cast(mask, tf.float32)
    mask /= tf.reduce_mean(mask)
    mask = tf.where(tf.is_nan(mask), tf.zeros_like(mask), mask)
    loss = tf.square(tf.subtract(preds, labels))
    loss = loss * mask
    loss = tf.where(tf.is_nan(loss), tf.zeros_like(loss), loss)
    return tf.reduce_mean(loss)


def masked_mae_tf(preds, labels, null_val=np.nan):
    """
    Accuracy with masking.
    :param preds:
    :param labels:
    :param null_val:
    :return:
    """
    if np.isnan(null_val):
        mask = ~tf.is_nan(labels)
    else:
        mask = tf.not_equal(labels, null_val)
    mask = tf.cast(mask, tf.float32)
    mask /= tf.reduce_mean(mask)
    mask = tf.where(tf.is_nan(mask), tf.zeros_like(mask), mask)
    loss = tf.abs(tf.subtract(preds, labels))
    loss = loss * mask
    loss = tf.where(tf.is_nan(loss), tf.zeros_like(loss), loss)
    return tf.reduce_mean(loss)


def masked_rmse_tf(preds, labels, null_val=np.nan):
    """
    Accuracy with masking.
    :param preds:
    :param labels:
    :param null_val:
    :return:
    """
    return tf.sqrt(masked_mse_tf(preds=preds, labels=labels, null_val=null_val))


def masked_rmse_np(preds, labels, null_val=np.nan):
    return np.sqrt(masked_mse_np(preds=preds, labels=labels, null_val=null_val))


def masked_mse_np(preds, labels, null_val=np.nan):
    with np.errstate(divide='ignore', invalid='ignore'):
        if np.isnan(null_val):
            mask = ~np.isnan(labels)
        else:
            mask = np.not_equal(labels, null_val)
        mask = mask.astype('float32')
        mask /= np.mean(mask)
        rmse = np.square(np.subtract(preds, labels)).astype('float32')
        rmse = np.nan_to_num(rmse * mask)
        return np.mean(rmse)


def masked_mae_np(preds, labels, null_val=np.nan):
    with np.errstate(divide='ignore', invalid='ignore'):
        if np.isnan(null_val):
            mask = ~np.isnan(labels)
        else:
            mask = np.not_equal(labels, null_val)
        mask = mask.astype('float32')
        mask /= np.mean(mask)
        mae = np.abs(np.subtract(preds, labels)).astype('float32')
        mae = np.nan_to_num(mae * mask)
        return np.mean(mae)

'''
def masked_mape_np(preds, labels, null_val=np.nan):
    with np.errstate(divide='ignore', invalid='ignore'):
        if np.isnan(null_val):
            mask = ~np.isnan(labels)
        else:
            mask = np.not_equal(labels, null_val)
        mask = mask.astype('float32')
        mask /= np.mean(mask)
        mape = np.abs(np.divide(np.subtract(preds, labels).astype('float32'), labels))
        mape = np.nan_to_num(mask * mape)
        return np.mean(mape)
'''
def masked_mape_np(preds, labels, null_val=pd.NA):
    with np.errstate(divide='ignore', invalid='ignore'):
        if pd.isna(null_val):
            mask = ~pd.isna(labels)
        else:
            mask = np.not_equal(labels, null_val)
        mask = mask.astype('float32')
        mask /= np.mean(mask)
        mape = np.abs(np.divide(np.subtract(preds, labels).astype('float32'), labels))
        mape = np.nan_to_num(mask * mape)
        return np.mean(mape)


# Builds loss function.
def masked_mse_loss(scaler, null_val):
    def loss(preds, labels):
        if scaler:
            preds = scaler.inverse_transform(preds)
            labels = scaler.inverse_transform(labels)
        return masked_mse_tf(preds=preds, labels=labels, null_val=null_val)

    return loss


def masked_rmse_loss(scaler, null_val):
    def loss(preds, labels):
        if scaler:
            preds = scaler.inverse_transform(preds)
            labels = scaler.inverse_transform(labels)
        return masked_rmse_tf(preds=preds, labels=labels, null_val=null_val)

    return loss


def masked_mae_loss(scaler, null_val):
    def loss(preds, labels):
        if scaler:
            preds = scaler.inverse_transform(preds)
            labels = scaler.inverse_transform(labels)
        mae = masked_mae_tf(preds=preds, labels=labels, null_val=null_val)
        return mae

    return loss


def calculate_metrics(df_pred, df_test, null_val):
    """
    Calculate the MAE, MAPE, RMSE
    :param df_pred:
    :param df_test:
    :param null_val:
    :return:
    """
    mape = masked_mape_np(preds=df_pred.to_numpy(), labels=df_test.to_numpy(), null_val=null_val)
    mae = masked_mae_np(preds=df_pred.to_numpy(), labels=df_test.to_numpy(), null_val=null_val)
    rmse = masked_rmse_np(preds=df_pred.to_numpy(), labels=df_test.to_numpy(), null_val=null_val)
    return [mae, mape, rmse]

"""#Baseline Algorithms

Lagged Variables
Input - AQI(t), AQI(t-1),..., AQI(t-24) + Weather vars (t,....,t-24)

Output - AQI(t+1), AQI(t+6), AQI(t+12), AQI(t+18), AQI(t+24) (Multi-output prediction)

###Linear Regression
"""

pred = {k:[] for k in [1,6,12,18,24]}
gt = {k:[] for k in [1,6,12,18,24]}

for sensor in sensors:
    
    start = time.time()
    
    df_temp = df.loc[:,[i for i in df.columns.tolist() if i.endswith(sensor)]]
    
    for col in ['aqi','at','rh','ws','wd']: 
        for j in range(1,24):
            df_temp['p{}_{}'.format(j,col)] = df_temp[col + '_%s' % sensor]
            df_temp['p{}_{}'.format(j,col)] = df_temp['p{}_{}'.format(j,col)].shift(j)

    for j in [1,6,12,18,24]:
        df_temp['hz{}'.format(j)] = df_temp['aqi_%s' % sensor]
        #df_temp['hz{}'.format(j)] = df_temp['meo_%s' % sensor]
        df_temp['hz{}'.format(j)] = df_temp['hz{}'.format(j)].shift(-j)
    
    y_cols = [i for i in df_temp.columns.tolist() if i.startswith('hz')]
    x_cols = [i for i in df_temp.columns.tolist() if i.startswith('hz')==False]
    
    X = df_temp.loc[:,x_cols]    
    y = df_temp.loc[:,y_cols]
    
    X_train = X.loc[:pd.Timestamp('2019-12-31 23:00:00'),:]
    y_train = y.loc[:pd.Timestamp('2019-12-31 23:00:00'),:]
    X_test = X.loc[pd.Timestamp('2020-01-01 00:00:00'):,:]
    y_test = y.loc[pd.Timestamp('2020-01-01 00:00:00'):,:]
    
    #nik
    train = pd.concat([X_train,y_train],axis=1)
    train.dropna(axis=0,how='any',inplace=True)
    X_train = train.loc[:,x_cols]
    y_train = train.loc[:,y_cols]
    
    #nik
    X_test.fillna(X_test.mean(),inplace=True)

    model = MultiTaskLassoCV(alphas=[0.1,1,10,100],cv=3)
    model.fit(X_train,y_train)
    
    predictions = model.predict(X_test)
    actual = np.array(y_test)
    
    j=0
    for i in [1,6,12,18,24]:
        pred[i].append(predictions[:,j].tolist())
        gt[i].append(actual[:,j].tolist())
        j = j + 1
        
    end = time.time()

    print(sensor+'='+str(np.round(end-start,2)))

pred = {k:[] for k in [1,6,12,18,24]}
gt = {k:[] for k in [1,6,12,18,24]}

for sensor in sensors:
    
    start = time.time()
    
    df_temp = df.loc[:,[i for i in df.columns.tolist() if i.endswith(sensor)]]
    
    for col in ['aqi','at','rh','ws','wd']: 
        for j in range(1,24):
            df_temp['p{}_{}'.format(j,col)] = df_temp[col + '_%s' % sensor]
            df_temp['p{}_{}'.format(j,col)] = df_temp['p{}_{}'.format(j,col)].shift(j)

    for j in [1,6,12,18,24]:
        df_temp['hz{}'.format(j)] = df_temp['aqi_%s' % sensor]
        df_temp['hz{}'.format(j)] = df_temp['hz{}'.format(j)].shift(-j)
    
    y_cols = [i for i in df_temp.columns.tolist() if i.startswith('hz')]
    x_cols = [i for i in df_temp.columns.tolist() if i.startswith('hz')==False]
    
    X = df_temp.loc[:,x_cols]    
    y = df_temp.loc[:,y_cols]
    
    X_train = X.loc[:pd.Timestamp('2019-12-31 23:00:00'),:]
    y_train = y.loc[:pd.Timestamp('2019-12-31 23:00:00'),:]
    X_test = X.loc[pd.Timestamp('2020-01-01 00:00:00'):,:]
    y_test = y.loc[pd.Timestamp('2020-01-01 00:00:00'):,:]
    
    #nik
    train = pd.concat([X_train,y_train],axis=1)
    train.dropna(axis=0,how='any',inplace=True)
    X_train = train.loc[:,x_cols]
    y_train = train.loc[:,y_cols]
    
    #nik
    X_test.fillna(X_test.mean(),inplace=True)

    model = MultiTaskLassoCV(alphas=[0.1,1,10,100],cv=3)
    model.fit(X_train,y_train)
    
    predictions = model.predict(X_test)
    actual = np.array(y_test)
    
    j=0
    for i in [1,6,12,18,24]:
        pred[i].append(predictions[:,j].tolist())
        gt[i].append(actual[:,j].tolist())
        j = j + 1
        
    end = time.time()
    
    print(sensor+'='+str(np.round(end-start,2)))

result_mape = {k:[] for k in [1,6,12,18,24]}
result_mae = {k:[] for k in [1,6,12,18,24]}
result_rmse = {k:[] for k in [1,6,12,18,24]}

for i in gt.keys():
    res = calculate_metrics(pd.DataFrame(np.array(pred[i]).T),pd.DataFrame(np.array(gt[i]).T),np.nan)
    result_mape[i] = res[1]
    result_mae[i] = res[0]
    result_rmse[i] = res[2]

final_dict = {k:[] for k in [1,6,12,18,24]}
for i in [1,6,12,18,24]:
    final_dict[i].append(np.round(result_mae[i],2))
    final_dict[i].append(np.round(result_rmse[i],2))
    final_dict[i].append(np.round(result_mape[i],2))

for i in [1,6,12,18,24]:
    for j in final_dict[i]:
        print(j)

"""###VAR"""

pred = {k:[] for k in [1,6,12,18,24]}
gt = {k:[] for k in [1,6,12,18,24]}

for sensor in sensors:
    
    start = time.time()
    
    df_temp = df.loc[:,[i for i in df.columns.tolist()]]
    
    for k in sensors:
        for col in ['aqi','at','rh','ws','wd']:
            for j in range(1,24):
                df_temp['p{}_{}_{}'.format(j,k,col)] = df_temp[col + '_%s' % k]
                df_temp['p{}_{}_{}'.format(j,k,col)] = df_temp['p{}_{}_{}'.format(j,k,col)].shift(j)
    
    for j in [1,6,12,18,24]:
        df_temp['hz{}'.format(j)] = df_temp['aqi_%s' % sensor]
        df_temp['hz{}'.format(j)] = df_temp['hz{}'.format(j)].shift(-j)
    
    y_cols = [i for i in df_temp.columns.tolist() if i.startswith('hz')]
    x_cols = [i for i in df_temp.columns.tolist() if i.startswith('hz')==False]
    
    X = df_temp.loc[:,x_cols]    
    y = df_temp.loc[:,y_cols]
    
    X_train = X.loc[:pd.Timestamp('2019-12-31 23:00:00'),:]
    y_train = y.loc[:pd.Timestamp('2019-12-31 23:00:00'),:]
    X_test = X.loc[pd.Timestamp('2020-01-01 00:00:00'):,:]
    y_test = y.loc[pd.Timestamp('2020-01-01 00:00:00'):,:]
    
    #nik
    train = pd.concat([X_train,y_train],axis=1)
    train.dropna(axis=0,how='any',inplace=True)
    X_train = train.loc[:,x_cols]
    y_train = train.loc[:,y_cols]
    
    #nik
    X_test.fillna(X_test.mean(),inplace=True)

    model = MultiTaskLassoCV(alphas=[1,10,100],cv=3)
    model.fit(X_train,y_train)
    
    predictions = model.predict(X_test)
    actual = np.array(y_test)
    
    j=0
    for i in [1,6,12,18,24]:
        pred[i].append(predictions[:,j].tolist())
        gt[i].append(actual[:,j].tolist())
        j = j + 1
        
    end = time.time()
    
    print(sensor+'='+str(np.round(end-start,2)))

for i in pred.keys():
    pred_csv = pd.DataFrame(np.array(pred[i])).T
    pred_csv.columns = ['pred_{}'.format(sensor) for sensor in sensors]
    pred_csv.index = X_test.index
    gt_csv = pd.DataFrame(np.array(gt[i])).T
    gt_csv.columns = ['actual_{}'.format(sensor) for sensor in sensors]
    gt_csv.index = X_test.index
    main_csv = pd.concat([pred_csv,gt_csv],axis=1)
    #main_csv.to_csv('/Users/nikmag/Desktop/var_horizon_{}_output.csv'.format(i))

pred.keys()

result_mape = {k:[] for k in [1,6,12,18,24]}
result_mae = {k:[] for k in [1,6,12,18,24]}
result_rmse = {k:[] for k in [1,6,12,18,24]}

for i in gt.keys():
    res = calculate_metrics(pd.DataFrame(np.array(pred[i]).T),pd.DataFrame(np.array(gt[i]).T),np.nan)
    result_mape[i] = res[1]
    result_mae[i]= res[0]
    result_rmse[i]= res[2]

final_dict = {k:[] for k in [1,6,12,18,24]}
for i in [1,6,12,18,24]:
    final_dict[i].append(np.round(result_mae[i],2))
    final_dict[i].append(np.round(result_rmse[i],2))
    final_dict[i].append(np.round(result_mape[i],2))

for i in [1,6,12,18,24]:
    for j in final_dict[i]:
        print(j)

"""###GBM"""

pred = {k:[] for k in [1,6,12,18,24]}
gt = {k:[] for k in [1,6,12,18,24]}

result_mape = {k:[] for k in [1,6,12,18,24]}
result_mae = {k:[] for k in [1,6,12,18,24]}
result_rmse = {k:[] for k in [1,6,12,18,24]}

for sensor in sensors:
    
    start = time.time()
    
    df_temp = df.loc[:,[i for i in df.columns.tolist() if i.endswith(sensor)]]
    
    for col in ['aqi','at','rh','ws','wd']: 
        for j in range(1,24):
            df_temp['p{}_{}'.format(j,col)] = df_temp[col + '_%s' % sensor]
            df_temp['p{}_{}'.format(j,col)] = df_temp['p{}_{}'.format(j,col)].shift(j)

    for j in [1,6,12,18,24]:
        df_temp['hz{}'.format(j)] = df_temp['aqi_%s' % sensor]
        df_temp['hz{}'.format(j)] = df_temp['hz{}'.format(j)].shift(-j)
    
    y_cols = [i for i in df_temp.columns.tolist() if i.startswith('hz')]
    x_cols = [i for i in df_temp.columns.tolist() if i.startswith('hz')==False]
    
    X = df_temp.loc[:,x_cols]    
    y = df_temp.loc[:,y_cols]
    
    X_train = X.loc[:pd.Timestamp('2019-12-31 23:00:00'),:]
    y_train = y.loc[:pd.Timestamp('2019-12-31 23:00:00'),:]
    X_test = X.loc[pd.Timestamp('2020-01-01 00:00:00'):,:]
    y_test = y.loc[pd.Timestamp('2020-01-01 00:00:00'):,:]
    
    #nik
    train = pd.concat([X_train,y_train],axis=1)
    train.dropna(axis=0,how='any',inplace=True)
    X_train = train.loc[:,x_cols]
    y_train = train.loc[:,y_cols]
    
    #nik
    X_test.fillna(X_test.mean(),inplace=True)

    gbm = GradientBoostingRegressor(learning_rate=0.05,max_features=0.6,max_leaf_nodes=31,n_estimators=200)
    model = MultiOutputRegressor(gbm,n_jobs=-1)
    model.fit(X_train,y_train)
    
    predictions = model.predict(X_test)
    actual = np.array(y_test)

    j=0
    for i in [1,6,12,18,24]:
        pred[i].append(predictions[:,j].tolist())
        gt[i].append(actual[:,j].tolist())
        j = j + 1
        
    end = time.time()
    
    print(sensor+'='+str(np.round(end-start,2)))

result_mape = {k:[] for k in [1,6,12,18,24]}
result_mae = {k:[] for k in [1,6,12,18,24]}
result_rmse = {k:[] for k in [1,6,12,18,24]}

for i in gt.keys():
    res = calculate_metrics(pd.DataFrame(np.array(pred[i]).T),pd.DataFrame(np.array(gt[i]).T),np.nan)
    result_mape[i] = res[1]
    result_mae[i]= res[0]
    result_rmse[i]= res[2]

final_dict = {k:[] for k in [1,6,12,18,24]}
for i in [1,6,12,18,24]:
    final_dict[i].append(np.round(result_mae[i],2))
    final_dict[i].append(np.round(result_rmse[i],2))
    final_dict[i].append(np.round(result_mape[i],2))

for i in [1,6,12,18,24]:
    for j in final_dict[i]:
        print(j)

"""###RF"""

pred = {k:[] for k in [1,6,12,18,24]}
gt = {k:[] for k in [1,6,12,18,24]}

result_mape = {k:[] for k in [1,6,12,18,24]}
result_mae = {k:[] for k in [1,6,12,18,24]}
result_rmse = {k:[] for k in [1,6,12,18,24]}

for sensor in sensors:
    
    start = time.time()
    
    df_temp = df.loc[:,[i for i in df.columns.tolist() if i.endswith(sensor)]]
    
    for col in ['aqi','at','rh','ws','wd']: 
        for j in range(1,24):
            df_temp['p{}_{}'.format(j,col)] = df_temp[col + '_%s' % sensor]
            df_temp['p{}_{}'.format(j,col)] = df_temp['p{}_{}'.format(j,col)].shift(j)

    for j in [1,6,12,18,24]:
        df_temp['hz{}'.format(j)] = df_temp['aqi_%s' % sensor]
        df_temp['hz{}'.format(j)] = df_temp['hz{}'.format(j)].shift(-j)
    
    y_cols = [i for i in df_temp.columns.tolist() if i.startswith('hz')]
    x_cols = [i for i in df_temp.columns.tolist() if i.startswith('hz')==False]
    
    X = df_temp.loc[:,x_cols]    
    y = df_temp.loc[:,y_cols]
    
    X_train = X.loc[:pd.Timestamp('2019-12-31 23:00:00'),:]
    y_train = y.loc[:pd.Timestamp('2019-12-31 23:00:00'),:]
    X_test = X.loc[pd.Timestamp('2020-01-01 00:00:00'):,:]
    y_test = y.loc[pd.Timestamp('2020-01-01 00:00:00'):,:]
    
    #nik
    train = pd.concat([X_train,y_train],axis=1)
    train.dropna(axis=0,how='any',inplace=True)
    X_train = train.loc[:,x_cols]
    y_train = train.loc[:,y_cols]
    
    #nik
    X_test.fillna(X_test.mean(),inplace=True)

    model = RandomForestRegressor(n_estimators=600)
    model.fit(X_train,y_train)
    
    predictions = model.predict(X_test)
    actual = np.array(y_test)
    
    j=0
    for i in [1,6,12,18,24]:
        pred[i].append(predictions[:,j].tolist())
        gt[i].append(actual[:,j].tolist())
        j = j + 1
        
    end = time.time()
    
    print(sensor+'='+str(np.round(end-start,2)))

result_mape = {k:[] for k in [1,6,12,18,24]}
result_mae = {k:[] for k in [1,6,12,18,24]}
result_rmse = {k:[] for k in [1,6,12,18,24]}

for i in gt.keys():
    res = calculate_metrics(pd.DataFrame(np.array(pred[i]).T),pd.DataFrame(np.array(gt[i]).T),np.nan)
    result_mape[i] = res[1]
    result_mae[i]= res[0]
    result_rmse[i]= res[2]

final_dict = {k:[] for k in [1,6,12,18,24]}
for i in [1,6,12,18,24]:
    final_dict[i].append(np.round(result_mae[i],2))
    final_dict[i].append(np.round(result_rmse[i],2))
    final_dict[i].append(np.round(result_mape[i],2))

for i in [1,6,12,18,24]:
    for j in final_dict[i]:
        print(j)

"""#Spatial Model"""

import numpy as np
import pandas as pd
import time
from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import LinearRegression, RidgeCV, MultiTaskLassoCV, LassoCV
from sklearn.metrics import mean_squared_error
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR
from sklearn.multioutput import MultiOutputRegressor
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.tree import DecisionTreeRegressor
import lightgbm as lgb
import tensorflow as tf
from sklearn.neural_network import MLPRegressor

pred_ann = {k:[] for k in range(1,13)}
gt = {k:[] for k in range(1,13)}

for sensor in sensors:
    
    start = time.time()
    
    #current AQI and Weather data
    df_temp = df.loc[:,[i for i in df.columns.tolist()]]
    
    #next 48 hour prediction
    for j in range(1,49):
        df_temp['hz{}'.format(j)] = df_temp['aqi_%s' % sensor]
        df_temp['hz{}'.format(j)] = df_temp['hz{}'.format(j)].shift(-j)
        
    df_temp['hz7_12_min'] = df_temp[['hz{}'.format(i) for i in range(7,13)]].min(1)
    df_temp['hz7_12_max'] = df_temp[['hz{}'.format(i) for i in range(7,13)]].max(1)
    
    df_temp['hz13_24_min'] = df_temp[['hz{}'.format(i) for i in range(13,25)]].min(1)
    df_temp['hz13_24_max'] = df_temp[['hz{}'.format(i) for i in range(13,25)]].max(1)
    
    df_temp['hz25_48_min'] = df_temp[['hz{}'.format(i) for i in range(25,49)]].min(1)
    df_temp['hz25_48_max'] = df_temp[['hz{}'.format(i) for i in range(25,49)]].max(1)
    
    df_temp.drop(columns=['hz{}'.format(i) for i in range(7,49)],axis=1,inplace=True)
    
    df_temp.drop(columns=[col for col in df_temp if col.endswith(sensor)],axis=1,inplace=True)
    
    #past 12 hours AQI data
    sensors1 = [s for s in sensors if s!= sensor]
    for k in sensors1:
        for col in ['aqi']: 
            for j in range(1,13):
                df_temp['p{}_{}_{}'.format(j,k,col)] = df_temp[col + '_%s' % k]
                df_temp['p{}_{}_{}'.format(j,k,col)] = df_temp['p{}_{}_{}'.format(j,k,col)].shift(j)
    
    y_cols = [i for i in df_temp.columns.tolist() if i.startswith('hz')]
    x_cols = [i for i in df_temp.columns.tolist() if i.startswith('hz')==False]
    
    X = df_temp.loc[:,x_cols]    
    y = df_temp.loc[:,y_cols]
    
    X_train = X.loc[:pd.Timestamp('2020-08-31 23:00:00'),:]
    y_train = y.loc[:pd.Timestamp('2020-08-31 23:00:00'),:]
    X_test = X.loc[pd.Timestamp('2020-09-01 00:00:00'):pd.Timestamp('2020-12-31 23:00:00'),:]
    y_test = y.loc[pd.Timestamp('2020-09-01 00:00:00'):pd.Timestamp('2020-12-31 23:00:00'),:]
    
    train = pd.concat([X_train,y_train],axis=1)
    train.dropna(axis=0,how='any',inplace=True)
    X_train = train.loc[:,x_cols]
    y_train = train.loc[:,y_cols]
    
    X_test.fillna(X_test.mean(),inplace=True)

    model = MLPRegressor(hidden_layer_sizes=(100),max_iter=250,learning_rate='adaptive')
    spatial_fit = model.fit(X_train,y_train)
    
    predictions = model.predict(X_test)
    actual = np.array(y_test)
    
    j=0
    for i in range(1,13):
        pred_ann[i].append(predictions[:,j].tolist())
        gt[i].append(actual[:,j].tolist())
        j = j + 1
        
    end = time.time()
    
    print(sensor+'='+str(np.round(end-start,2)))

"""#Temporal Model"""

pred_lr = {k:[] for k in range(1,13)}
#gt = {k:[] for k in range(1,13)}

for sensor in sensors:
    
    start = time.time()
    
    #current AQI
    df_temp = df.loc[:,[i for i in df.columns.tolist() if i.endswith(sensor)]]
    
    #past 12 hours data
    for col in ['aqi','at','rh','ws','wd']: 
        for j in range(1,13):
            df_temp['p{}_{}'.format(j,col)] = df_temp[col + '_%s' % sensor]
            df_temp['p{}_{}'.format(j,col)] = df_temp['p{}_{}'.format(j,col)].shift(j)
    
    #weather forecast for 48 hours
    for col in ['at','rh','ws','wd']:
        for j in range(1,49):
            df_temp['f{}_{}'.format(j,col)] = df_temp[col + '_%s' % sensor]
            df_temp['f{}_{}'.format(j,col)] = df_temp['f{}_{}'.format(j,col)].shift(-j)

        df_temp['f7_12_min_{}'.format(col)] = df_temp[['f{}_{}'.format(k,col) for k in range(7,13)]].min(1)
        df_temp['f7_12_max_{}'.format(col)] = df_temp[['f{}_{}'.format(k,col) for k in range(7,13)]].max(1)
        df_temp['f13_24_min_{}'.format(col)] = df_temp[['f{}_{}'.format(k,col) for k in range(13,25)]].min(1)
        df_temp['f13_24_max_{}'.format(col)] = df_temp[['f{}_{}'.format(k,col) for k in range(13,25)]].max(1)
        df_temp['f25_48_min_{}'.format(col)] = df_temp[['f{}_{}'.format(k,col) for k in range(25,49)]].min(1)
        df_temp['f25_48_max_{}'.format(col)] = df_temp[['f{}_{}'.format(k,col) for k in range(25,49)]].max(1)
        
        df_temp.drop(columns=['f{}_{}'.format(k,col) for k in range(7,49)],axis=1,inplace=True)
        
    #HourOfDay and DayOfWeek
    df_temp['hourofday'] = df_temp.index.hour
    df_temp['dayofweek'] = df_temp.index.dayofweek
    df_temp['hourofday'] = df_temp['hourofday'].apply(str)
    df_temp['dayofweek'] = df_temp['dayofweek'].apply(str)
    
    #next 48 hour prediction
    for j in range(1,49):
        df_temp['hz{}'.format(j)] = df_temp['aqi_%s' % sensor]
        df_temp['hz{}'.format(j)] = df_temp['hz{}'.format(j)].shift(-j)
        
    df_temp['hz7_12_min'] = df_temp[['hz{}'.format(i) for i in range(7,13)]].min(1)
    df_temp['hz7_12_max'] = df_temp[['hz{}'.format(i) for i in range(7,13)]].max(1)
    
    df_temp['hz13_24_min'] = df_temp[['hz{}'.format(i) for i in range(13,25)]].min(1)
    df_temp['hz13_24_max'] = df_temp[['hz{}'.format(i) for i in range(13,25)]].max(1)
    
    df_temp['hz25_48_min'] = df_temp[['hz{}'.format(i) for i in range(25,49)]].min(1)
    df_temp['hz25_48_max'] = df_temp[['hz{}'.format(i) for i in range(25,49)]].max(1)
    
    df_temp.drop(columns=['hz{}'.format(i) for i in range(7,49)],axis=1,inplace=True)
    
    y_cols = [i for i in df_temp.columns.tolist() if i.startswith('hz')]
    x_cols = [i for i in df_temp.columns.tolist() if i.startswith('hz')==False]
    
    X = df_temp.loc[:,x_cols]    
    y = df_temp.loc[:,y_cols]
    
    X_train = X.loc[:pd.Timestamp('2020-08-31 23:00:00'),:]
    y_train = y.loc[:pd.Timestamp('2020-08-31 23:00:00'),:]
    X_test = X.loc[pd.Timestamp('2020-09-01 00:00:00'):pd.Timestamp('2020-12-31 23:00:00'),:]
    y_test = y.loc[pd.Timestamp('2020-09-01 00:00:00'):pd.Timestamp('2020-12-31 23:00:00'),:]
    
    train = pd.concat([X_train,y_train],axis=1)
    train.dropna(axis=0,how='any',inplace=True)
    X_train = train.loc[:,x_cols]
    y_train = train.loc[:,y_cols]
    
    X_test.fillna(X_test.mean(),inplace=True)

    model = MultiTaskLassoCV(alphas=[0.1,1,10],cv=3)
    temporal_fit = model.fit(X_train,y_train)
    
    predictions = model.predict(X_test)
    actual = np.array(y_test)
    
    j=0
    for i in range(1,13):
        pred_lr[i].append(predictions[:,j].tolist())
        #gt[i].append(actual[:,j].tolist())
        j = j + 1
        
    end = time.time()
    
    print(sensor+'='+str(np.round(end-start,2)))

"""#Prediction Aggregator (decision tree)"""

df_gt = pd.DataFrame()
for h in range(1,13):
    df_gt = pd.concat([df_gt,pd.DataFrame(np.array(gt[h]).T)\
              .rename(columns = {i: "{}_".format(h) + sensor for i,sensor in enumerate(sensors)})],axis = 1)

df_ann = pd.DataFrame()
for h in range(1,13):
    df_ann = pd.concat([df_ann,pd.DataFrame(np.array(pred_ann[h]).T)\
               .rename(columns = {i: "{}_".format(h) + sensor for i,sensor in enumerate(sensors)})],axis = 1)

df_lr = pd.DataFrame()
for h in range(1,13):
    df_lr = pd.concat([df_lr,pd.DataFrame(np.array(pred_lr[h]).T)\
              .rename(columns = {i: "{}_".format(h) + sensor for i,sensor in enumerate(sensors)})],axis = 1)

tempr = df_ann.copy()
df_train_ann = tempr[:int(0.7*(len(tempr)))]
df_test_ann = tempr[int(0.7*(len(tempr))):]

tempr2 = df_lr.copy()
df_train_lr = tempr2[:int(0.7*(len(tempr2)))]
df_test_lr = tempr2[int(0.7*(len(tempr2))):]

df_test_pred = pd.DataFrame(columns = df_gt.columns)
df_test_gt = df_lr.loc[2049:2927, ]

for col in df_gt.columns.tolist():
    X_train = pd.concat([df_train_ann[col],df_train_lr[col]], axis=1)
    y_train = df_gt[col]
    X_test = pd.concat([df_test_ann[col],df_test_lr[col]], axis=1)
    
    X_test.fillna(X_test.mean(),inplace=True)
    
    train = pd.concat([X_train,y_train],axis=1)
    train.dropna(axis=0,how='any',inplace=True)
    X_train = train.iloc[:,[0,1]]
    y_train = train.iloc[:,2]
    
    model = DecisionTreeRegressor()
    model.fit(X_train,y_train)
    
    df_test_pred[col] = model.predict(X_test)

for i in range(1,13):
    cols = [col for col in df_test_pred.columns.tolist() if col.startswith(str(i)+"_")]
    res = calculate_metrics(df_test_pred[cols],df_test_gt[cols],np.nan)
    print(res[0])
    print(res[2])
    print(res[1])